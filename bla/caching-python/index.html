<!DOCTYPE html>
<html lang="en">

<head>
    <title>Caching computation in Python | Heitor&#x27;s log</title>
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="robots" content="noodp"/>

    <link rel="stylesheet" href="https://heitorpb.github.io/style.css">
    <link rel="stylesheet" href="https://heitorpb.github.io/color/green.css">

        <link rel="stylesheet" href="https://heitorpb.github.io/color/background_dark.css">
    
    <link rel="stylesheet" href="https://heitorpb.github.io/font-hack-subset.css">

            
        <link rel="alternate" type="application/atom+xml" title="RSS" href="https://heitorpb.github.io/atom.xml">
    
<!-- KaTeX css and JS -->
<link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>

<script defer>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          // customised options
          // • auto-render specific keys, e.g.:
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '\\(', right: '\\)', display: false},
          ],
          // • rendering keys, e.g.:
          //throwOnError : false
        });
    });
</script>

</head>

<body class="">
<div class="container">
    
    <header class="header">
        <div class="header__inner">
            <div class="header__logo">
                    
                <a href="https://heitorpb.github.io" style="text-decoration: none;">
                    <div class="logo">
                      
                            Heitor&#x27;s Log
                        
                    </div>
                </a>
            </div>
        </div>

        
        <nav class="menu">
            <ul class="menu__inner">
                <li><a href="https://heitorpb.github.io">Home</a></li>
            
                <li><a href="https://heitorpb.github.io/me">About me</a></li>
            
                <li><a href="https://flickr.com/photos/heitorpb">Photos</a></li>
            
                <li class="active"><a href="https://heitorpb.github.io/bla">Articles</a></li>
            </ul>
        </nav>
    
    
        
    </header>
    

    <div class="content">
        
    <div class="post">
        
    <h1 class="post-title"><a href="https://heitorpb.github.io/bla/caching-python/">Caching computation in Python</a></h1>
    <div class="post-meta-inline">
        
    <span class="post-date">
            Jun 24, 2020
        </span>

    </div>

    
        <span class="post-tags-inline">
                :: tags:&nbsp;
                <a class="post-tag" href="https://heitorpb.github.io/tags/cache/">#cache</a>&nbsp;
                <a class="post-tag" href="https://heitorpb.github.io/tags/optimization/">#optimization</a>&nbsp;
                <a class="post-tag" href="https://heitorpb.github.io/tags/python/">#python</a></span>
    
    
    <br><div class="post-meta-inline"><small>
        Reading time: 6 minutes
    </small></div>
    

        
        <div class="post-content">
            <p>Caching is an optimization strategy that stores data in some memory, instead of
using and discarding it. The idea is to store data to serve if faster in the
future. This might save CPU time at the cost of increased memory usage.</p>
<p>There are many types of cache (hardware caches, network caches, software
caches…), with different applications and performances. In this post I will
discuss one type of software cache: <em>memoization</em>.</p>
<h2 id="memoization">Memoization</h2>
<p>Memoization is a software cache technique in which the results of functions
are saved in a cache. The entries of this cache are served when the function is
called with the same inputs, instead of executing the function again.</p>
<p>It has this name because it is a “memorization” process: it saves the output of
a function for a given input. Let’s see an example: the factorial. A Python
code of the recursive version is:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">factorial</span><span>(</span><span style="color:#bf616a;">n</span><span>):
</span><span>    </span><span style="color:#b48ead;">if </span><span>n &gt; </span><span style="color:#d08770;">1</span><span>:
</span><span>        </span><span style="color:#b48ead;">return </span><span>n * </span><span style="color:#bf616a;">factorial</span><span>(n - </span><span style="color:#d08770;">1</span><span>)
</span><span>    </span><span style="color:#b48ead;">else</span><span>:
</span><span>        </span><span style="color:#b48ead;">return </span><span style="color:#d08770;">1
</span></code></pre>
<p>Every time this function is called, it calculates \( (n-1)! \),
\( (n-2)! \), \( (n-3)! \), \( (n-4)! \), …, this is very fast for small
values of \(n\), but it can take some time for larger inputs:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>In [</span><span style="color:#d08770;">3</span><span>]: %timeit </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">30</span><span>)
</span><span style="color:#d08770;">3.6 </span><span>µs ± </span><span style="color:#d08770;">81.5 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">100000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">4</span><span>]: %timeit </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">50</span><span>)
</span><span style="color:#d08770;">7.4 </span><span>µs ± </span><span style="color:#d08770;">1.16 </span><span>µs per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">100000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">5</span><span>]: %timeit </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">100</span><span>)
</span><span style="color:#d08770;">13.5 </span><span>µs ± </span><span style="color:#d08770;">92.3 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">100000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">16</span><span>]: %timeit </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">1000</span><span>)
</span><span style="color:#d08770;">294 </span><span>µs ± </span><span style="color:#d08770;">9.45 </span><span>µs per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">1000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">18</span><span>]: %timeit </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">2000</span><span>)
</span><span style="color:#d08770;">1.04 </span><span>ms ± </span><span style="color:#d08770;">128 </span><span>µs per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">1000 </span><span>loops each)
</span></code></pre>
<p>So, it takes longer to calculate more intermediate results. Let’s try to
memoize it manually:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">class </span><span style="color:#ebcb8b;">MemoizedFactorial</span><span style="color:#eff1f5;">:
</span><span>    </span><span style="color:#b48ead;">def </span><span style="color:#96b5b4;">__init__</span><span>(</span><span style="color:#bf616a;">self</span><span>):
</span><span>        </span><span style="color:#bf616a;">self</span><span>.cache = {}
</span><span>
</span><span>    </span><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">calculate</span><span>(</span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">n</span><span>):
</span><span>        </span><span style="color:#b48ead;">if </span><span>n in </span><span style="color:#bf616a;">self</span><span>.cache:
</span><span>            </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">self</span><span>.cache[n]
</span><span>        </span><span style="color:#b48ead;">else</span><span>:
</span><span>            </span><span style="color:#b48ead;">if </span><span>n &gt; </span><span style="color:#d08770;">1</span><span>:
</span><span>                </span><span style="color:#bf616a;">self</span><span>.cache[n] = n * </span><span style="color:#bf616a;">self</span><span>.</span><span style="color:#bf616a;">calculate</span><span>(n-</span><span style="color:#d08770;">1</span><span>)
</span><span>                </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">self</span><span>.cache[n]
</span><span>            </span><span style="color:#b48ead;">else</span><span>:
</span><span>                </span><span style="color:#bf616a;">self</span><span>.cache[</span><span style="color:#d08770;">1</span><span>] = </span><span style="color:#d08770;">1
</span><span>                </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">self</span><span>.cache[</span><span style="color:#d08770;">1</span><span>]
</span></code></pre>
<p>And to use it:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>x = </span><span style="color:#bf616a;">MemoizedFactorial</span><span>()
</span><span style="color:#96b5b4;">print</span><span>(x.</span><span style="color:#bf616a;">calculate</span><span>(</span><span style="color:#d08770;">5</span><span>)) </span><span style="color:#65737e;"># prints 120
</span></code></pre>
<p>And how fast it is?</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>In [</span><span style="color:#d08770;">20</span><span>]: %timeit x.</span><span style="color:#bf616a;">calculate</span><span>(</span><span style="color:#d08770;">2000</span><span>)
</span><span style="color:#d08770;">147 </span><span>ns ± </span><span style="color:#d08770;">0.877 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">10000000 </span><span>loops each)
</span></code></pre>
<p>So, about 150 ns vs 1 ms to calculate the same number.
It is only ~7000 times faster to calculate this version of \(2000!\).
And then there’s something interesting for \(n &lt; 2000\):</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>In [</span><span style="color:#d08770;">21</span><span>]: %timeit x.</span><span style="color:#bf616a;">calculate</span><span>(</span><span style="color:#d08770;">100</span><span>)
</span><span style="color:#d08770;">147 </span><span>ns ± </span><span style="color:#d08770;">2 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">10000000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">22</span><span>]: %timeit x.</span><span style="color:#bf616a;">calculate</span><span>(</span><span style="color:#d08770;">137</span><span>)
</span><span style="color:#d08770;">150 </span><span>ns ± </span><span style="color:#d08770;">0.896 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">10000000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">23</span><span>]: %timeit x.</span><span style="color:#bf616a;">calculate</span><span>(</span><span style="color:#d08770;">5</span><span>)
</span><span style="color:#d08770;">147 </span><span>ns ± </span><span style="color:#d08770;">2.47 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">10000000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">24</span><span>]: %timeit x.</span><span style="color:#bf616a;">calculate</span><span>(</span><span style="color:#d08770;">1234</span><span>)
</span><span style="color:#d08770;">175 </span><span>ns ± </span><span style="color:#d08770;">0.81 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">10000000 </span><span>loops each)
</span></code></pre>
<p>It takes roughly the same amount of time to “calculate” any value. And it is
expected: we are only retrieving values of a dictionary.</p>
<p>And notice the memory consumption for each function:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>In [</span><span style="color:#d08770;">25</span><span>]: </span><span style="color:#b48ead;">import </span><span>sys
</span><span>
</span><span>In [</span><span style="color:#d08770;">26</span><span>]: sys.</span><span style="color:#bf616a;">getsizeof</span><span>(x.cache)
</span><span>Out[</span><span style="color:#d08770;">26</span><span>]: </span><span style="color:#d08770;">73816
</span></code></pre>
<p>This trades a function to an object that holds 73 KB of cache and yields a
dramatic performance increase.</p>
<p>It stores 2000 results in 73KB, what would happen if we had 2 million entries?
And then continue calculating more million entries? This implementation would
keep consuming more and more memory until there’s no more space.</p>
<p>To overcome this situation, there are many
<a href="https://en.wikipedia.org/wiki/Cache_replacement_policies">caching algorithms</a>
that put in place policies to discard cached data when it becomes full. Here I will discuss the
<em>Least Recently Used</em> approach.</p>
<h2 id="least-recently-used-lru">Least Recently Used (LRU)</h2>
<p>It is important to define a maximum size for the cache. This way the system
does not grow indefinitely and you can have control about its memory
consumption.</p>
<p>The downside is to discard information when the cache is at its limit. One way
of doing so is keeping only the recent entries, discarding the least recently
used.</p>
<p>This is not as simple as the example above, because it needs to also keep track
of when each entry was cached. On the other hand, it is already implemented in
Python’s Standard Library :) The module
<a href="https://docs.python.org/3/library/functools.html"><code>functools</code></a> provides us the
decorator <code>lru_cache</code>:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">from </span><span>functools </span><span style="color:#b48ead;">import </span><span>lru_cache
</span><span>
</span><span>@</span><span style="color:#bf616a;">lru_cache</span><span>(</span><span style="color:#bf616a;">maxsize</span><span>=</span><span style="color:#d08770;">2000</span><span>)
</span><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">factorial</span><span>(</span><span style="color:#bf616a;">n</span><span>):
</span><span>    </span><span style="color:#b48ead;">if </span><span>n &gt; </span><span style="color:#d08770;">1</span><span>:
</span><span>        </span><span style="color:#b48ead;">return </span><span>n * </span><span style="color:#bf616a;">factorial</span><span>(n - </span><span style="color:#d08770;">1</span><span>)
</span><span>    </span><span style="color:#b48ead;">else</span><span>:
</span><span>        </span><span style="color:#b48ead;">return </span><span style="color:#d08770;">1
</span></code></pre>
<p>It is the same function from the first code, but with a decorator added. The
default maximum size of the cache is <code>128</code>, I increased so we can compare
the timings with our handmade version:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>In [</span><span style="color:#d08770;">27</span><span>]: %timeit </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">1000</span><span>)
</span><span style="color:#d08770;">68 </span><span>ns ± </span><span style="color:#d08770;">0.697 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">10000000 </span><span>loops each)
</span><span>
</span><span>In [</span><span style="color:#d08770;">28</span><span>]: %timeit </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">2000</span><span>)
</span><span style="color:#d08770;">64.1 </span><span>ns ± </span><span style="color:#d08770;">1.05 </span><span>ns per </span><span style="color:#bf616a;">loop </span><span>(mean ± std. dev. of </span><span style="color:#d08770;">7 </span><span>runs, </span><span style="color:#d08770;">10000000 </span><span>loops each)
</span></code></pre>
<p>This decorated function is almost three times faster than the handmade cache.</p>
<p>Another interesting advantage of this decorator is that it provides some
methods to see what happened with the cache:</p>
<ul>
<li>
<p>The <code>cache_info()</code> method displays some statistics about that cache: how many
<em>hits</em> (the number of times the requested data was in the cache), <em>misses</em>
(the number of times the requested data was not in the cache), the maximum
number of entries in the cache and the current number of cached items.</p>
</li>
<li>
<p>The <code>cache_clear()</code> method empties the cache.</p>
</li>
</ul>
<p>Let’s see them in action:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>In [</span><span style="color:#d08770;">13</span><span>]: factorial.</span><span style="color:#bf616a;">cache_clear</span><span>()
</span><span>
</span><span>In [</span><span style="color:#d08770;">14</span><span>]: factorial.</span><span style="color:#bf616a;">cache_info</span><span>()
</span><span>Out[</span><span style="color:#d08770;">14</span><span>]: </span><span style="color:#bf616a;">CacheInfo</span><span>(</span><span style="color:#bf616a;">hits</span><span>=</span><span style="color:#d08770;">0</span><span>, </span><span style="color:#bf616a;">misses</span><span>=</span><span style="color:#d08770;">0</span><span>, </span><span style="color:#bf616a;">maxsize</span><span>=</span><span style="color:#d08770;">2000</span><span>, </span><span style="color:#bf616a;">currsize</span><span>=</span><span style="color:#d08770;">0</span><span>)
</span><span>
</span><span>In [</span><span style="color:#d08770;">15</span><span>]: </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">1000</span><span>)
</span><span>Out[</span><span style="color:#d08770;">15</span><span>]: </span><span style="color:#d08770;">402387260077093773543702433923003985719374864210714632543799910429938512398629020592044208486969404800479988610197196058631666872994808558901323829669944590997424504087073759918823627727188732519779505950995276120874975462497043601418278094646496291056393887437886487337119181045825783647849977012476632889835955735432513185323958463075557409114262417474349347553428646576611667797396668820291207379143853719588249808126867838374559731746136085379534524221586593201928090878297308431392844403281231558611036976801357304216168747609675871348312025478589320767169132448426236131412508780208000261683151027341827977704784635868170164365024153691398281264810213092761244896359928705114964975419909342221566832572080821333186116811553615836546984046708975602900950537616475847728421889679646244945160765353408198901385442487984959953319101723355556602139450399736280750137837615307127761926849034352625200015888535147331611702103968175921510907788019393178114194545257223865541461062892187960223838971476088506276862967146674697562911234082439208160153780889893964518263243671616762179168909779911903754031274622289988005195444414282012187361745992642956581746628302955570299024324153181617210465832036786906117260158783520751516284225540265170483304226143974286933061690897968482590125458327168226458066526769958652682272807075781391858178889652208164348344825993266043367660176999612831860788386150279465955131156552036093988180612138558600301435694527224206344631797460594682573103790084024432438465657245014402821885252470935190620929023136493273497565513958720559654228749774011413346962715422845862377387538230483865688976461927383814900140767310446640259899490222221765904339901886018566526485061799702356193897017860040811889729918311021171229845901641921068884387121855646124960798722908519296819372388642614839657382291123125024186649353143970137428531926649875337218940694281434118520158014123344828015051399694290153483077644569099073152433278288269864602789864321139083506217095002597389863554277196742822248757586765752344220207573630569498825087968928162753848863396909959826280956121450994871701244516461260379029309120889086942028510640182154399457156805941872748998094254742173582401063677404595741785160829230135358081840096996372524230560855903700624271243416909004153690105933983835777939410970027753472000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
</span><span>
</span><span>In [</span><span style="color:#d08770;">16</span><span>]: factorial.</span><span style="color:#bf616a;">cache_info</span><span>()
</span><span>Out[</span><span style="color:#d08770;">16</span><span>]: </span><span style="color:#bf616a;">CacheInfo</span><span>(</span><span style="color:#bf616a;">hits</span><span>=</span><span style="color:#d08770;">0</span><span>, </span><span style="color:#bf616a;">misses</span><span>=</span><span style="color:#d08770;">1000</span><span>, </span><span style="color:#bf616a;">maxsize</span><span>=</span><span style="color:#d08770;">2000</span><span>, </span><span style="color:#bf616a;">currsize</span><span>=</span><span style="color:#d08770;">1000</span><span>)
</span><span>
</span><span>In [</span><span style="color:#d08770;">17</span><span>]: </span><span style="color:#bf616a;">factorial</span><span>(</span><span style="color:#d08770;">1000</span><span>)
</span><span>Out[</span><span style="color:#d08770;">17</span><span>]: </span><span style="color:#d08770;">402387260077093773543702433923003985719374864210714632543799910429938512398629020592044208486969404800479988610197196058631666872994808558901323829669944590997424504087073759918823627727188732519779505950995276120874975462497043601418278094646496291056393887437886487337119181045825783647849977012476632889835955735432513185323958463075557409114262417474349347553428646576611667797396668820291207379143853719588249808126867838374559731746136085379534524221586593201928090878297308431392844403281231558611036976801357304216168747609675871348312025478589320767169132448426236131412508780208000261683151027341827977704784635868170164365024153691398281264810213092761244896359928705114964975419909342221566832572080821333186116811553615836546984046708975602900950537616475847728421889679646244945160765353408198901385442487984959953319101723355556602139450399736280750137837615307127761926849034352625200015888535147331611702103968175921510907788019393178114194545257223865541461062892187960223838971476088506276862967146674697562911234082439208160153780889893964518263243671616762179168909779911903754031274622289988005195444414282012187361745992642956581746628302955570299024324153181617210465832036786906117260158783520751516284225540265170483304226143974286933061690897968482590125458327168226458066526769958652682272807075781391858178889652208164348344825993266043367660176999612831860788386150279465955131156552036093988180612138558600301435694527224206344631797460594682573103790084024432438465657245014402821885252470935190620929023136493273497565513958720559654228749774011413346962715422845862377387538230483865688976461927383814900140767310446640259899490222221765904339901886018566526485061799702356193897017860040811889729918311021171229845901641921068884387121855646124960798722908519296819372388642614839657382291123125024186649353143970137428531926649875337218940694281434118520158014123344828015051399694290153483077644569099073152433278288269864602789864321139083506217095002597389863554277196742822248757586765752344220207573630569498825087968928162753848863396909959826280956121450994871701244516461260379029309120889086942028510640182154399457156805941872748998094254742173582401063677404595741785160829230135358081840096996372524230560855903700624271243416909004153690105933983835777939410970027753472000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
</span><span>
</span><span>In [</span><span style="color:#d08770;">18</span><span>]: factorial.</span><span style="color:#bf616a;">cache_info</span><span>()
</span><span>Out[</span><span style="color:#d08770;">18</span><span>]: </span><span style="color:#bf616a;">CacheInfo</span><span>(</span><span style="color:#bf616a;">hits</span><span>=</span><span style="color:#d08770;">1</span><span>, </span><span style="color:#bf616a;">misses</span><span>=</span><span style="color:#d08770;">1000</span><span>, </span><span style="color:#bf616a;">maxsize</span><span>=</span><span style="color:#d08770;">2000</span><span>, </span><span style="color:#bf616a;">currsize</span><span>=</span><span style="color:#d08770;">1000</span><span>)
</span></code></pre>
<p>After emptying the cache, there’s no information apart the maximum size. The
first time the function is called, there will be only misses as the cache is
empty. The second time this function is called, the result is already
available.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Caching is an optimization technique in which we trade expensive computation
for memory. This memory, of course, needs to have a faster access than
computing the data again. As a consequence, the cache needs to be small.</p>
<p>To keep the cache under control, a number of caching strategies exists. The
Least Recently Used approach is an efficient way to keep only the most
recently used entries. It is available in Python as
<a href="https://docs.python.org/3/library/functools.html#functools.lru_cache"><code>functools.lru_cache</code></a>.</p>

        </div>

        
        <div class="pagination">
            <div class="pagination__title">
                <span class="pagination__title-h">Thanks for reading! Read other posts?</span>
                <hr />
            </div>
            <div class="pagination__buttons">
                    <span class="button previous">
                        <a href="https://heitorpb.github.io/bla/utf-8-files/">
                            <span class="button__icon">←</span>&nbsp;
                            <span class="button__text">Convert files to UTF-8</span>
                        </a>
                    </span>
                
                
                    <span class="button next">
                        <a href="https://heitorpb.github.io/bla/git-multiple-remotes/">
                            <span class="button__text">Multiple urls for a git remote</span>&nbsp;
                            <span class="button__icon">→</span>
                        </a>
                    </span>
                </div>
        </div>
    
    </div>

    </div>

    
    <footer class="footer">
        <div class="footer__inner">
                <div class="copyright copyright--user">© 2018 Heitor de Bittencourt</div>
            </div>
    </footer>
    

</div>
</body>

</html>
